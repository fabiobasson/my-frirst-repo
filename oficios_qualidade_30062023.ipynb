{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiobasson/my-repo/blob/main/oficios_qualidade_30062023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "uta-25E8gflL",
        "outputId": "f86e4a31-087b-47e5-c67b-a07bb62163ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3a612310-e9bf-4a52-9471-689f7dc705fc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3a612310-e9bf-4a52-9471-689f7dc705fc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Preciso criar um diretorio chamado laudo e jogar os oficios para dentro do mesmo (arquivos.pdf)\n",
        "! mkdir -p laudo\n",
        "! cd laudo\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixWeXvJC0NK3",
        "outputId": "3e40870c-b5d9-451a-c8f0-7966f2afaf04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://y05r:****@inet-sys.petrobras.com.br:804/\n",
            "Requirement already satisfied: camelot-py[cv] in c:\\programdata\\anaconda3\\lib\\site-packages (0.11.0)\n",
            "Requirement already satisfied: openpyxl>=2.5.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (3.0.10)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (0.8.10)\n",
            "Requirement already satisfied: pdfminer.six>=20200726 in c:\\programdata\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (20221105)\n",
            "Requirement already satisfied: pypdf>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (3.9.0)\n",
            "Requirement already satisfied: pandas>=0.23.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (1.21.5)\n",
            "Requirement already satisfied: click>=6.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (8.0.4)\n",
            "Requirement already satisfied: chardet>=3.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (4.0.0)\n",
            "Requirement already satisfied: pdftopng>=0.2.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (0.2.3)\n",
            "Requirement already satisfied: ghostscript>=0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (0.7)\n",
            "Requirement already satisfied: opencv-python>=3.4.2.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from camelot-py[cv]) (4.7.0.72)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=6.7->camelot-py[cv]) (0.4.5)\n",
            "Requirement already satisfied: setuptools>=38.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ghostscript>=0.7->camelot-py[cv]) (63.4.1)\n",
            "Requirement already satisfied: et_xmlfile in c:\\programdata\\anaconda3\\lib\\site-packages (from openpyxl>=2.5.8->camelot-py[cv]) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->camelot-py[cv]) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->camelot-py[cv]) (2.8.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer.six>=20200726->camelot-py[cv]) (37.0.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer.six>=20200726->camelot-py[cv]) (2.0.4)\n",
            "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pypdf>=3.0.0->camelot-py[cv]) (4.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py[cv]) (1.15.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.23.4->camelot-py[cv]) (1.16.0)\n",
            "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py[cv]) (2.21)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'apt-get' nÆo ‚ reconhecido como um comando interno\n",
            "ou externo, um programa oper vel ou um arquivo em lotes.\n",
            "O sistema nÆo pode encontrar o arquivo especificado.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://y05r:****@inet-sys.petrobras.com.br:804/\n",
            "Could not fetch URL https://y05r:****@inet-sys.petrobras.com.br:804/pypi-org/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='inet-sys.petrobras.com.br', port=804): Max retries exceeded with url: /pypi-org/ (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))) - skipping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /pypi-org/\n",
            "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /pypi-org/\n",
            "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /pypi-org/\n",
            "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /pypi-org/\n",
            "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /pypi-org/\n",
            "ERROR: Could not find a version that satisfies the requirement pypi.org (from versions: none)\n",
            "ERROR: No matching distribution found for pypi.org\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://y05r:****@inet-sys.petrobras.com.br:804/\n",
            "Requirement already satisfied: pdfminer.six in c:\\programdata\\anaconda3\\lib\\site-packages (20221105)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer.six) (37.0.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Looking in indexes: https://y05r:****@inet-sys.petrobras.com.br:804/\n",
            "Requirement already satisfied: pdfreader in c:\\programdata\\anaconda3\\lib\\site-packages (0.1.12)\n",
            "Requirement already satisfied: bitarray>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfreader) (2.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfreader) (2.8.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfreader) (9.2.0)\n",
            "Requirement already satisfied: pycryptodome>=3.9.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfreader) (3.18.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pdfreader) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# instalação de pacotes e bibliotecas\n",
        "\n",
        "#!git clone https://www.github.com/camelot-dev/camelot\n",
        "#!cd camelot\n",
        "!pip install   \"camelot-py[cv]\"\n",
        "\n",
        "!apt-get install  ghostscript\n",
        "\n",
        "!pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org  'PyPDF2<3.0'\n",
        "!pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org  pypi.org xlwt\n",
        "\n",
        "!pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org  pdfminer.six\n",
        "\n",
        "!pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org  pdfreader\n",
        "\n",
        "import camelot\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "import glob\n",
        "\n",
        "from pdfreader import PDFDocument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoToSjcKRnp7",
        "outputId": "02e693b5-dd58-449c-f2f5-9be8e9c363dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "posicao: 0 e valor:C:\\Users\\y05r\\Downloads\\laudo\\Laudo_2628256_7_BUZ_33_RJS_22111210.pdf \n",
            "posicao: 1 e valor:C:\\Users\\y05r\\Downloads\\laudo\\Laudo_2628563_7_RI_26_BA_221110214.pdf \n",
            "posicao: 2 e valor:C:\\Users\\y05r\\Downloads\\laudo\\Laudo_2787644_8_SEP_5D_RJS_230110033.pdf \n",
            "posicao: 3 e valor:C:\\Users\\y05r\\Downloads\\laudo\\Laudo_2891654_8_LL_118D_RJS_230310070.pdf \n",
            "posicao: 4 e valor:C:\\Users\\y05r\\Downloads\\laudo\\Laudo_3014818_9_RO_138D_RJS_230410093.pdf \n",
            "posicao: 5 e valor:C:\\Users\\y05r\\Downloads\\laudo\\Laudo_3047648.pdf \n",
            "posicao: 6 e valor:C:\\Users\\y05r\\Downloads\\laudo\\Laudo_3069378_7_SEP_6_RJS_230510100.pdf \n",
            "posicao: 7 e valor:C:\\Users\\y05r\\Downloads\\laudo\\Laudo_3069866_7_SEP_8D_RJS_230510101.pdf \n",
            "posicao: 8 e valor:C:\\Users\\y05r\\Downloads\\laudo\\Laudo_3146346_7_RO_148HP_RJS_230610103.pdf \n",
            "posicao: 9 e valor:C:\\Users\\y05r\\Downloads\\laudo\\Laudo_3146667_9_BUZ_40D_RJS_230610104.pdf \n",
            "posicao: 10 e valor:C:\\Users\\y05r\\Downloads\\laudo\\Laudo_3147277_9_RO_172D_RJS_230610105 (1).pdf \n"
          ]
        }
      ],
      "source": [
        "# Use glob to get a list of all CSV/PDF files in the folder\n",
        "path_colab = r'/content/laudo/*.pdf'\n",
        "path_jupyter_laptop = r'C:\\Users\\basson\\Downloads\\DSA\\python\\laudo\\*.pdf'\n",
        "path_jupyter_desktop = r'C:\\Users\\y05r\\Downloads\\laudo\\*.pdf'\n",
        "\n",
        "files = glob.glob(path_colab)\n",
        "files = glob.glob(path_jupyter_laptop)\n",
        "files = glob.glob(path_jupyter_desktop)\n",
        "\n",
        "# Loop through the files\n",
        "\n",
        "for i in range(0, len(files), 1):\n",
        "    print(f'posicao: {i} e valor:{files[i]} ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m7OII1MughZT",
        "outputId": "3b2bdc6c-7903-47a4-e28b-c72435bb0149"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Can not find Ghostscript DLL in registry",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14452\\169763737.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# Lendo documento .pdf e extraindo as tabela com a biblioteca Camelot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m           \u001b[0mlista_tabelas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamelot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"all\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Criando Dataframe após extração das tabelas do arquivo .pdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\camelot\\io.py\u001b[0m in \u001b[0;36mread_pdf\u001b[1;34m(filepath, pages, password, flavor, suppress_stdout, layout_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPDFHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpassword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_extra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflavor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         tables = p.parse(\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[0mflavor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0msuppress_stdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuppress_stdout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\camelot\\handlers.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, flavor, suppress_stdout, layout_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLattice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mflavor\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"lattice\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m                 t = parser.extract_tables(\n\u001b[0m\u001b[0;32m    177\u001b[0m                     \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuppress_stdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuppress_stdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                 )\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\camelot\\parsers\\lattice.py\u001b[0m in \u001b[0;36mextract_tables\u001b[1;34m(self, filename, suppress_stdout, layout_kwargs)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimagename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_table_bbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\camelot\\backends\\ghostscript_backend.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, pdf_path, png_path, resolution)\u001b[0m\n\u001b[0;32m     34\u001b[0m             )\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mghostscript\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         gs_command = [\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ghostscript\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;31m# :todo: remove, debugging only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_gsprint\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ghostscript\\_gsprint.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[0mlibgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__win32_finddll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlibgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Can not find Ghostscript DLL in registry'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m     \u001b[0mlibgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwindll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Can not find Ghostscript DLL in registry"
          ]
        }
      ],
      "source": [
        "#\n",
        "resultado = pd.DataFrame()\n",
        "\n",
        "for file in files:\n",
        "    with open(file, 'rb') as pdf:\n",
        "        #doc = PDFDocument(pdf)\n",
        "        #print(f'posicao: {file} e valor:{files[file]} ')\n",
        "        # Lendo documento .pdf e extraindo as tabela com a biblioteca Camelot\n",
        "\n",
        "          lista_tabelas = camelot.read_pdf(file,header=None,index=False,encoding=\"utf-8\",pages=\"all\")\n",
        "\n",
        "        # Criando Dataframe após extração das tabelas do arquivo .pdf\n",
        "          lista_tabelas = lista_tabelas[0].df[[1,0,2]].reset_index(drop=True)\n",
        "\n",
        "        ### Iniciando o ETL da extração das tabelas ###\n",
        "\n",
        "        # remover as linhas e colunas desnecessárias a extração das informações\n",
        "          lista_tabelas = lista_tabelas.drop(0, axis='index')\n",
        "          lista_tabelas = lista_tabelas.drop(1, axis='index')\n",
        "\n",
        "        # Renomear as colunas para o padrão do documento\n",
        "          lista_tabelas.rename(columns = {1:'Norma Referencia',0:'Tipo Dados',2:'Situacao BDIEP'}, inplace = True)\n",
        "\n",
        "          lista_tabelas = lista_tabelas.loc[lista_tabelas['Situacao BDIEP'] == 'NÃO CONFORME']\n",
        "          print(\"\\n\")\n",
        "\n",
        "        # Extraindo texto do documento com a biblioteca Extract_text\n",
        "          texto = extract_text(file, 'rb')\n",
        "\n",
        "        # Criando Dataframe após extração das tabelas do arquivo .pdf\n",
        "          texto = pd.read_fwf(io.StringIO(texto))\n",
        "          texto = texto[16:22]\n",
        "\n",
        "        # Iniciando o ETL da extração do texto\n",
        "\n",
        "        # remover linhas e colunas desnecessárias a extração das informações\n",
        "\n",
        "        # Renomear colunas para o padrão do documento\n",
        "          texto.rename(columns = {'Agencia Nacional de Petróleo, Gás Natura e Biocombustíveis':' CABEÇALHO'}, inplace = True)\n",
        "          texto = texto.T\n",
        "          texto.rename(columns = {16:'Nº do Laudo de Reprovação', 17:'Data da Avaliação',18:'Nome do Poço',19:'Nº Cadastro do Poço',20:'Conclusão do Poço',21:'Empresa Operadora'}, inplace = True)\n",
        "\n",
        "        ##\n",
        "          search_for = \"NÃO CONFORMIDADES\" # What to search in the log lines...\n",
        "          line_num = 0 # Line number\n",
        "          lines_found = 0 # Quantity of lines found...\n",
        "          out_file = \"saida.txt\"\n",
        "          in_file = \"texto.txt\"\n",
        "\n",
        "          with open(out_file, 'w') as out_file:\n",
        "            with open(in_file, \"r\") as in_file:\n",
        "              for line in in_file:\n",
        "                line_num += 1\n",
        "                if search_for in line:\n",
        "                  lines_found += 1\n",
        "                  print(\"Found '{}' in line {}...\".format(search_for, line_num))\n",
        "                  print(\"Found '{}' \".format(line))\n",
        "                  out_file.write(line)\n",
        "              print(\"Found {} lines...\".format(lines_found))\n",
        "\n",
        "\n",
        "          concatenar = pd.concat([texto,lista_tabelas],ignore_index=True)\n",
        "          concatenar.shape\n",
        "          display(concatenar)\n",
        "          print(\"\\n\")\n",
        "\n",
        "          resultado = pd.concat([resultado,concatenar])\n",
        "\n",
        "          # Saida do dataframe para um planilha excel\n",
        "          #concatenar.to_excel('file_name.xls')\n",
        "\n",
        "resultado.to_excel('file_name.xls')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cme6v7UK6gmv",
        "outputId": "b3fce0b6-5f4a-4720-9e23-213670c28179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conteúdo da página 1:\n",
            "Agencia Nacional de Petróleo, Gás Natura e Biocombustíveis\n",
            "Superintendência de Dados Técnicos\n",
            "Banco de Dados de Exploração e Produção\n",
            "Laudo de Avaliação de Dados de Poço\n",
            "2305.1.0099 7-MRO-6DB-RJS 74316029648 23/02/2021 Petrobras1.1. Nº do Laudo \n",
            "de Reprovação:1.2. Data da \n",
            "Avaliação :1.3. Nome do \n",
            "Poço:1.4. Nº Cadastro do \n",
            "Poço:1.5. Conclusão do \n",
            "Poço:1.6. Empresa \n",
            "Operadora:1. CABEÇALHO\n",
            "08/05/2023\n",
            "2.3. Código de Cadastro da(s) \n",
            "Mídia(s) no BDEP:2.2. Data de Protocolo da(s) \n",
            "Remessa(s):2.1. Número de Protocolo da(s) \n",
            "Remessa(s):2. CONTROLE DE REMESSAS (USO INTERNO)\n",
            "48610.202029/2021-13 370_2021 14/05/2021\n",
            "48610.202029/2021-13 385_2021 17/05/2021\n",
            "*Legenda da Situação dos Dados de Poço no BDEP:\n",
            "NÃO RECEBIDO = Conjunto de dados adquiridos pela operadora, conforme Notificação de Perfilagem Realizada (NPR), mas não \n",
            "remetidos ao BDEP;\n",
            "NÃO CONFORME = Conjunto de dados avaliados como não conformes. As não conformidades estão descritas neste laudo;\n",
            "APROVADO = Conjunto de dados aprovados e carregados no banco de dados. 3. RELAÇÃO DE DADOS RECEBIDOS\n",
            "Situação dos Dados no BDEP*: Tipos de Dados : Norma de Referência:\n",
            "RANP n° 880/2022\n",
            "RANP n° 880/2022\n",
            "RANP n° 880/2022\n",
            "RANP n° 880/2022\n",
            "RANP n° 880/2022\n",
            "RANP n° 880/2022\n",
            "RANP n° 880/2022\n",
            "RANP n° 880/2022\n",
            "RANP n° 880/2022RANP n° 880/2022\n",
            "RANP n° 880/2022\n",
            "ANP08 3.12. Teste de Formação3.11. Perfil de Acompanhamento Geológico (PAG) - Anexos I, II e III3.10. Perfil Composto3.9. Perfil Digital Processado3.8. Perfis Especiais - Amostrador Lateral3.7. Perfis Especiais - Sísmica de Poço3.6. Perfis Especiais - Teste de Formação a Cabo3.5. Perfis Convencionais3.4. Perfis Durante a Perfuração3.3. Arquivos Auxiliares - Relatório de Campo de Sísmica 3.2. Arquivos Auxiliares - Dados Direcionais3.1. Arquivos Auxiliares - Esquemas de Ferramentas NÃO CONFORME\n",
            "APROVADO\n",
            "APROVADO\n",
            "APROVADO\n",
            "APROVADO\n",
            "4. RELAÇÃO DOS ARQUIVOS REPROVADOS\n",
            "Itens: Localização (Diretórios/Pastas): Nome do(s) Arquivo(s) Não \n",
            "Conforme(s):Relação das Não Conformidades:\n",
            "/000385_2021 7-mro-6db-rjs_bhpt_cast_xrmi_esq_ f\n",
            "erramentas.pdf6.1. Esquemas de Ferramentas 4.1,00\n",
            "/000385_2021 7-mro-6db-rjs_dll-msfl-sdl-dsn_gem _\n",
            "mril_csng_esq_ferramentas.pdf6.1. Esquemas de Ferramentas 4.2,00\n",
            "/000370_2021 BSAT _7-MRO-6DB-RJS_2A_290120\n",
            "21_BHA.pdf6.1. Esquemas de Ferramentas 4.3,00\n",
            "Itens: Não Conformidades:5. NÃO CONFORMIDADES REFERENTES À REMESSA DE DADOS , À ESTRUTURA DE DIRETÓRIOS E AO FORMATO E \n",
            "NOMENCLATURA DOS ARQUIVOS\n",
            "Page 1 of 4 7-MRO-6DB-RJS Laudo de Avaliação do Poço\n",
            "\n",
            "\n",
            "Conteúdo da página 2:\n",
            "5.1. Remessa de Dados\n",
            "5.2. Estrutura de Diretórios\n",
            "5.3. Formato / Nomenclatura\n",
            "6. NÃO CONFORMIDADES REFERENTES AOS RELATÓRIOS E ARQUIVOS AUXILIARES\n",
            "Não Conformidades: Itens:\n",
            "., ., Ausência do valor associado ao Cadastro de Poço. Valor esperado : \n",
            "74316029648.6.1. Esquemas de Ferramentas\n",
            "6.2. Dados Direcionais\n",
            "6.3. Rel. Sísmica de Poço\n",
            "7. NÃO CONFORMIDADES REFERENTES AO CABEÇALHO DE PERFIS DE POÇO (DURANTE A PERFURAÇÃO , \n",
            "CONVENCIONAIS, ESPECIAIS, COMPOSTO E DE ACOMPANHAMENTO GEOLÓGICO )\n",
            "Itens: Não Conformidades:\n",
            "7.1. Identificação do poço, \n",
            "bloco/campo e operador\n",
            "7.2. Informações e \n",
            "Referências de profundidades\n",
            "7.3. Identificação do perfil\n",
            "7.4. Coordenadas \n",
            "(geográficas/ retangulares)\n",
            "7.5. Informação de fluido de \n",
            "perfuração\n",
            "7.6. Informação de \n",
            "revestimento\n",
            "7.7. Informação de broca \n",
            "7.8. Datas \n",
            "7.9. Escala vertical \n",
            "7.10. Mapa de localização e \n",
            "esquema de poço \n",
            "7.11. Identificação da sonda de \n",
            "perfuração\n",
            "7.12. Resumo de perfilagens \n",
            "7.13. Legenda litológica, \n",
            "operacional \n",
            "7.14. Idioma\n",
            "7. 15. Outros\n",
            "Itens: Não Conformidades:8. NÃO CONFORMIDADES REFERENTES AO CORPO DE PERFIS DE POÇO (DURANTE A PERFURAÇÃO , \n",
            "CONVENCIONAIS, ESPECIAIS, COMPOSTO E DE ACOMPANHAMENTO GEOLÓGICO )\n",
            "8.1. Profundidades \n",
            "Perfiladas\n",
            "Page 2 of 4 7-MRO-6DB-RJS Laudo de Avaliação do Poço\n",
            "\n",
            "\n",
            "Conteúdo da página 3:\n",
            "8.2. Unidades físicas das \n",
            "curvas\n",
            "8.3. Largura das colunas ou \n",
            "faixas (tracks)\n",
            "8.4. Grade e divisão das \n",
            "colunas ou faixas (tracks)\n",
            "8.5. Tipo de informações \n",
            "associadas às colunas ou \n",
            "faixas (tracks)\n",
            "8.6. Identificação das curvas\n",
            "8.7. Estilo da linha das \n",
            "curvas\n",
            "8.8. Cor da linha das curvas\n",
            "8.9. Escala horizontal das \n",
            "curvas\n",
            "8.10. Anotações\n",
            "8.11. Resolução gráfica\n",
            "8.12. Informações na \n",
            "descrição\n",
            "8.13. Outros\n",
            "9. NÃO CONFORMIDADES REFERENTES AO RODAPÉ DO PERFIL COMPOSTO E DO PERFIL DE ACOMPANHAMENTO \n",
            "GEOLÓGICO\n",
            "Itens: Não Conformidades:\n",
            "9.1. Resumo dos testes de \n",
            "formação por tubulação ou a \n",
            "cabo\n",
            "9.2. Tabela de amostras \n",
            "laterais/testemunhos\n",
            "9.3. Tabela de sísmica de \n",
            "Poço\n",
            "9.4. Informações das brocas\n",
            "9.5. Método de cálculo para \n",
            "tempo de retorno do fluido de \n",
            "perfuração\n",
            "9.6. Outros\n",
            "10.CONCLUSÃO\n",
            "Os dados de arquivos auxiliares de ESQUEMAS DE FERRAMENTAS adquiridos pela companhia de perfilagem \n",
            "HALLIBURTON estão avaliados como NÃO CONFORMES. Corrigir o (s) arquivo(s ) reprovado(s ) discriminado(s ) no \n",
            "item 4 deste laudo de acordo com a relação das não conformidades. Reenviar todos os arquivos deste conjunto de \n",
            "dados ao BDEP, após a correção de suas não conformidades com a Resolução ANP n° 880 de 2022.\n",
            "Page 3 of 4 7-MRO-6DB-RJS Laudo de Avaliação do Poço\n",
            "\n",
            "\n",
            "Conteúdo da página 4:\n",
            "11. PREVISÃO LEGAL\n",
            "12. CONTATO11.1. Arts. 8 e 22, da Lei Nº 9.478/1997;\n",
            "11.2. Art. 4, do Decreto Nº 2455/1998;\n",
            "11.3. Art. 20, da Portaria ANP Nº 69/2011;\n",
            "11.4. Arts. 28 e 34, da Resolução ANP Nº 11/2011.\n",
            "13. REFERÊNCIAS PARA ENVIO DE DADOS À ANPPARA ENVIO DE DADOS TÉCNICOS , DOCUMENTOS E ASSUNTOS TÉCNICOS :\n",
            "Superintendência de Dados Técnicos\n",
            "Av. Pasteur, 404 - Bloco A 4 - Urca | Rio de Janeiro - RJ - Brasil | CEP: 22290-255\n",
            "Tel.: (55 - 21) 3545- 0112 / 3545-0175 | Fax: (55 - 21) 2244-0139\n",
            "E-mail: data_download@bdep.gov.br\n",
            "A Resolução ANP n° 880/2022 e Padrão ANP 8 encontram-se disponíveis para download no site eletrônico da ANP.\n",
            "https://www.gov.br/anp/pt-br/assuntos/exploracao-e-producao-de-oleo-e-gas/dados-tecnicos/legislacao-aplicavel\n",
            "https://www.gov.br/anp/pt-br/assuntos/exploracao-e-producao-de-oleo-e-gas/dados-tecnicos/legislacao-aplicavel\n",
            "Page 4 of 4 7-MRO-6DB-RJS Laudo de Avaliação do Poço\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import PyPDF2\n",
        "\n",
        "with open(r'/content/laudo/Laudo_3047648.pdf', 'rb') as arquivo:\n",
        "    leitor_pdf = PyPDF2.PdfReader(arquivo)\n",
        "\n",
        "    # Obtém o número total de páginas do PDF\n",
        "\n",
        "    total_paginas = len(leitor_pdf.pages)\n",
        "\n",
        "    for numero_pagina in range(total_paginas):\n",
        "\n",
        "        pagina = leitor_pdf.pages[numero_pagina]\n",
        "\n",
        "        texto = pagina.extract_text()\n",
        "\n",
        "        # Faça algo com o texto extraído da página\n",
        "        print(f\"Conteúdo da página {numero_pagina + 1}:\")\n",
        "        print(texto)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        f = open(\"texto.txt\", \"a+\")\n",
        "        f.write(\"\\n\" + texto)\n",
        "        f.close()\n",
        "\n",
        "#display(texto_pagina0.split(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "NOfv4o3x5UEW",
        "outputId": "b9e428dd-7f16-4849-c00a-2cdff6190f45"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Agencia Nacional de Petróleo, Gás Natura e BiocombustíveisSuperintendência de Dados TécnicosBanco de Dados de Exploração e ProduçãoLaudo de Avaliação de Dados de Poço2305.1.00997-MRO-6DB-RJS7431602964823/02/2021Petrobras1.1. Nº do Laudo de Reprovação:1.2. Data da Avaliação:1.3. Nome do Poço:1.4. Nº Cadastro do Poço:1.5. Conclusão do Poço:1.6. Empresa Operadora:1. CABEÇALHO08/05/20232.3. Código de Cadastro da(s) Mídia(s) no BDEP:2.2. Data de Protocolo da(s) Remessa(s):2.1. Número de Protocolo da(s) Remessa(s):2. CONTROLE DE REMESSAS (USO INTERNO)48610.202029/2021-13370_202114/05/202148610.202029/2021-13385_202117/05/2021*Legenda da Situação dos Dados de Poço no BDEP:NÃO RECEBIDO = Conjunto de dados adquiridos pela operadora, conforme Notificação de Perfilagem Realizada (NPR), mas não remetidos ao BDEP;NÃO CONFORME = Conjunto de dados avaliados como não conformes. As não conformidades estão descritas neste laudo;APROVADO = Conjunto de dados aprovados e carregados no banco de dados. 3. RELAÇÃO DE DADOS RECEBIDOSSituação dos Dados no BDEP*:Tipos de Dados:Norma de Referência:RANP n° 880/2022RANP n° 880/2022RANP n° 880/2022RANP n° 880/2022RANP n° 880/2022RANP n° 880/2022RANP n° 880/2022RANP n° 880/2022RANP n° 880/2022RANP n° 880/2022RANP n° 880/2022ANP083.12. Teste de Formação3.11. Perfil de Acompanhamento Geológico (PAG) - Anexos I, II e III3.10. Perfil Composto3.9. Perfil Digital Processado3.8. Perfis Especiais - Amostrador Lateral3.7. Perfis Especiais - Sísmica de Poço3.6. Perfis Especiais - Teste de Formação a Cabo3.5. Perfis Convencionais3.4. Perfis Durante a Perfuração3.3. Arquivos Auxiliares - Relatório de Campo de Sísmica 3.2. Arquivos Auxiliares - Dados Direcionais3.1. Arquivos Auxiliares - Esquemas de FerramentasNÃO CONFORMEAPROVADOAPROVADOAPROVADOAPROVADO4. RELAÇÃO DOS ARQUIVOS REPROVADOSItens:Localização (Diretórios/Pastas):Nome do(s) Arquivo(s) Não Conforme(s):Relação das Não Conformidades:/000385_20217-mro-6db-rjs_bhpt_cast_xrmi_esq_ferramentas.pdf6.1. Esquemas de Ferramentas4.1,00/000385_20217-mro-6db-rjs_dll-msfl-sdl-dsn_gem_mril_csng_esq_ferramentas.pdf6.1. Esquemas de Ferramentas4.2,00/000370_2021BSAT_7-MRO-6DB-RJS_2A_29012021_BHA.pdf6.1. Esquemas de Ferramentas4.3,00Itens:Não Conformidades:5. NÃO CONFORMIDADES REFERENTES À REMESSA DE DADOS, À ESTRUTURA DE DIRETÓRIOS E AO FORMATO E NOMENCLATURA DOS ARQUIVOSPage 1 of 47-MRO-6DB-RJSLaudo de Avaliação do Poço\\x0c5.1. Remessa de Dados5.2. Estrutura de Diretórios5.3. Formato / Nomenclatura6. NÃO CONFORMIDADES REFERENTES AOS RELATÓRIOS E ARQUIVOS AUXILIARESNão Conformidades:Itens:., ., Ausência do valor associado ao Cadastro de Poço. Valor esperado: 74316029648.6.1. Esquemas de Ferramentas6.2. Dados Direcionais6.3. Rel. Sísmica de Poço7. NÃO CONFORMIDADES REFERENTES AO CABEÇALHO DE PERFIS DE POÇO (DURANTE A PERFURAÇÃO, CONVENCIONAIS, ESPECIAIS, COMPOSTO E DE ACOMPANHAMENTO GEOLÓGICO)Itens:Não Conformidades:7.1. Identificação do poço, bloco/campo e operador7.2. Informações e Referências de profundidades7.3. Identificação do perfil7.4. Coordenadas (geográficas/ retangulares)7.5. Informação de fluido de perfuração7.6. Informação de revestimento7.7. Informação de broca 7.8. Datas 7.9. Escala vertical 7.10. Mapa de localização e esquema de poço 7.11. Identificação da sonda de perfuração7.12. Resumo de perfilagens 7.13. Legenda litológica, operacional 7.14. Idioma7. 15. OutrosItens:Não Conformidades:8. NÃO CONFORMIDADES REFERENTES AO CORPO DE PERFIS DE POÇO (DURANTE A PERFURAÇÃO, CONVENCIONAIS, ESPECIAIS, COMPOSTO E DE ACOMPANHAMENTO GEOLÓGICO)8.1. Profundidades PerfiladasPage 2 of 47-MRO-6DB-RJSLaudo de Avaliação do Poço\\x0c8.2. Unidades físicas das curvas8.3. Largura das colunas ou faixas (tracks)8.4. Grade e divisão das colunas ou faixas (tracks)8.5. Tipo de informações associadas às colunas ou faixas (tracks)8.6. Identificação das curvas8.7. Estilo da linha das curvas8.8. Cor da linha das curvas8.9. Escala horizontal das curvas8.10. Anotações8.11. Resolução gráfica8.12. Informações na descrição8.13. Outros9. NÃO CONFORMIDADES REFERENTES AO RODAPÉ DO PERFIL COMPOSTO E DO PERFIL DE ACOMPANHAMENTO GEOLÓGICOItens:Não Conformidades:9.1. Resumo dos testes de formação por tubulação ou a cabo9.2. Tabela de amostras laterais/testemunhos9.3. Tabela de sísmica de Poço9.4. Informações das brocas9.5. Método de cálculo para tempo de retorno do fluido de perfuração9.6. Outros10.CONCLUSÃOOs dados de arquivos auxiliares de ESQUEMAS DE FERRAMENTAS adquiridos pela companhia de perfilagem HALLIBURTON estão avaliados como NÃO CONFORMES. Corrigir o(s) arquivo(s) reprovado(s) discriminado(s) no item 4 deste laudo de acordo com a relação das não conformidades. Reenviar todos os arquivos deste conjunto de dados ao BDEP, após a correção de suas não conformidades com a Resolução ANP n° 880 de 2022.Page 3 of 47-MRO-6DB-RJSLaudo de Avaliação do Poço\\x0c11. PREVISÃO LEGAL12. CONTATO11.1. Arts. 8 e 22, da Lei Nº 9.478/1997;11.2. Art. 4, do Decreto Nº 2455/1998;11.3. Art. 20, da Portaria ANP Nº 69/2011;11.4. Arts. 28 e 34, da Resolução ANP Nº 11/2011.13. REFERÊNCIAS PARA ENVIO DE DADOS À ANPPARA ENVIO DE DADOS TÉCNICOS, DOCUMENTOS E ASSUNTOS TÉCNICOS:Superintendência de Dados TécnicosAv. Pasteur, 404 - Bloco A4 - Urca | Rio de Janeiro - RJ - Brasil | CEP: 22290-255Tel.: (55 - 21) 3545-0112 / 3545-0175 | Fax: (55 - 21) 2244-0139E-mail: data_download@bdep.gov.brA Resolução ANP n° 880/2022 e Padrão ANP8 encontram-se disponíveis para download no site eletrônico da ANP.https://www.gov.br/anp/pt-br/assuntos/exploracao-e-producao-de-oleo-e-gas/dados-tecnicos/legislacao-aplicavelhttps://www.gov.br/anp/pt-br/assuntos/exploracao-e-producao-de-oleo-e-gas/dados-tecnicos/legislacao-aplicavelPage 4 of 47-MRO-6DB-RJSLaudo de Avaliação do Poço\\x0c'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import io\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.pdfinterp import PDFPageInterpreter\n",
        "from pdfminer.pdfinterp import PDFResourceManager\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "# from pdfminer.pdfpage\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    resource_manager = PDFResourceManager()\n",
        "    fake_file_handle = io.StringIO()\n",
        "    converter = TextConverter(resource_manager, fake_file_handle)\n",
        "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
        "\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        page_content = []\n",
        "        for page in PDFPage.get_pages(file):\n",
        "            page_interpreter.process_page(page)\n",
        "\n",
        "            text_page = fake_file_handle.getvalue()\n",
        "            page_content.append(text_page)\n",
        "\n",
        "\n",
        "        # Contém o conteúdo do pdf completo\n",
        "        text = fake_file_handle.getvalue()\n",
        "\n",
        "    # close open handles\n",
        "    converter.close()\n",
        "    fake_file_handle.close()\n",
        "\n",
        "    if text:\n",
        "        return text, page_content\n",
        "\n",
        "\n",
        "extract_text_from_pdf(r'/content/laudo/Laudo_3047648.pdf')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il2hbhhiASha",
        "outputId": "f1fe71eb-a365-4643-b9f7-66b243b26734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 'NÃO CONFORMIDADES' in line 50...\n",
            "Found 'Itens: Não Conformidades:5. NÃO CONFORMIDADES REFERENTES À REMESSA DE DADOS , À ESTRUTURA DE DIRETÓRIOS E AO FORMATO E \n",
            "' \n",
            "Found 'NÃO CONFORMIDADES' in line 56...\n",
            "Found '6. NÃO CONFORMIDADES REFERENTES AOS RELATÓRIOS E ARQUIVOS AUXILIARES\n",
            "' \n",
            "Found 'NÃO CONFORMIDADES' in line 62...\n",
            "Found '7. NÃO CONFORMIDADES REFERENTES AO CABEÇALHO DE PERFIS DE POÇO (DURANTE A PERFURAÇÃO , \n",
            "' \n",
            "Found 'NÃO CONFORMIDADES' in line 88...\n",
            "Found 'Itens: Não Conformidades:8. NÃO CONFORMIDADES REFERENTES AO CORPO DE PERFIS DE POÇO (DURANTE A PERFURAÇÃO , \n",
            "' \n",
            "Found 'NÃO CONFORMIDADES' in line 113...\n",
            "Found '9. NÃO CONFORMIDADES REFERENTES AO RODAPÉ DO PERFIL COMPOSTO E DO PERFIL DE ACOMPANHAMENTO \n",
            "' \n",
            "Found 5 lines...\n"
          ]
        }
      ],
      "source": [
        "search_for = \"NÃO CONFORMIDADES\" # What to search in the log lines...\n",
        "line_num = 0 # Line number\n",
        "lines_found = 0 # Quantity of lines found...\n",
        "out_file = \"saida.txt\"\n",
        "in_file = \"texto.txt\"\n",
        "\n",
        "with open(out_file, 'w') as out_file:\n",
        "    with open(in_file, \"r\") as in_file:\n",
        "        for line in in_file:\n",
        "            line_num += 1\n",
        "            if search_for in line:\n",
        "                lines_found += 1\n",
        "                print(\"Found '{}' in line {}...\".format(search_for, line_num))\n",
        "                print(\"Found '{}' \".format(line))\n",
        "                out_file.write(line)\n",
        "        print(\"Found {} lines...\".format(lines_found))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JI1T7i7-1ts"
      },
      "outputs": [],
      "source": [
        "descproblema = ['Valor associado a menmonicos'],['Dados nao remetidos ao BDEP'],['Ausência de informação de perflagem conforme NPR '],['Valor inválido associado a mnemônicos '],['Cabeçalho '],['Valor inválido associado a mnemônicos'],['Ausência de informação de perflagem conforme NPR']\n",
        "df4 = pd.DataFrame(descproblema,columns=['Descrição do Problema'])\n",
        "\n",
        "df4 = df4.reset_index(drop=True)\n",
        "df4.info()\n",
        "#df4.rename(columns = {'16':'team_name', '17':'points_scored'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMP3bPup0jF1",
        "outputId": "b22b6a68-167f-485d-c21f-0a0b0fcf5f64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\python.exe: No module named spacy\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'spacy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-6-253ab6f2ec87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' python -m spacy download pt_core_news_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Import the Matcher\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatcher\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatcher\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
          ]
        }
      ],
      "source": [
        "! python -m spacy download pt_core_news_sm\n",
        "import spacy\n",
        "\n",
        "# Import the Matcher\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "import pt_core_news_sm\n",
        "nlp = pt_core_news_sm.load()\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "doc = nlp (texto)\n",
        "\n",
        "\n",
        "# Initialize the Matcher with the shared vocabulary\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Create a pattern matching two tokens: \"iPhone\" and \"X\"\n",
        "pattern = [{\"TEXT\": \"Laudo\"}, {\"TEXT\": \"de\"}]\n",
        "\n",
        "# Add the pattern to the matcher\n",
        "matcher.add(\"Não Conformidades_X_PATTERN\", [pattern])\n",
        "\n",
        "# Use the matcher on the doc\n",
        "matches = matcher(doc)\n",
        "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}